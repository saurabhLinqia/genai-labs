{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Embeddings with Pgvector\n",
    "##### using Sagemaker Jumpstart Foundation Models and Amazon RDS w/ Pgvector extension\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this lab we'll setup a Pgvector database table in an RDS Postgres instance, vectorize an SEC filing document, store the resulting embeddings in the database and then experiment with querying them\n",
    "\n",
    "---\n",
    "##### Lab Agenda:\n",
    "1. Setup dependencies\n",
    "2. Setup the database for Pgvector\n",
    "3. Setup the Text Embeddings model from a Sagemaker Endpoint\n",
    "4. Create Text Embeddings\n",
    "5. Vectorize an SEC filing document and store in Pgvector\n",
    "6. Test the database with some querying"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Setup dependencies\n",
    "check python version and import envrionment settings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the python version. should be 3.10.x\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment if you're running this on a new instance or kernel from lab 1 \n",
    "# !pip install --upgrade pip --quiet\n",
    "# !pip install --upgrade psycopg2 --quiet\n",
    "# !pip install --upgrade pgvector --quiet\n",
    "\n",
    "!pip install --upgrade tiktoken --quiet\n",
    "!pip install --upgrade langchain --quiet\n",
    "!pip install --upgrade sagemaker --quiet\n",
    "!pip install --upgrade beautifulsoup4 --quiet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, json\n",
    "sys.path.append(\"libs\")\n",
    "\n",
    "from sagemaker_embeddings_model import SagemakerEmbeddingsModel\n",
    "from sagemaker.session import Session\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from pgclient import PgClient\n",
    "from doc2vex import DocToVex\n",
    "import sagemaker_utils\n",
    "\n",
    "\n",
    "# TIKTOKEN_ENCODING = 'p50k_base'\n",
    "TEXT_EMBEDDING_ENDPOINT = \"### SET TEXT EMBEDDING ENDPOINT HERE ###\"\n",
    "EMBEDDING_VECTOR_SIZE = 384 # this depends on the model used to do the embeddings\n",
    "REGION = \"us-east-1\"\n",
    "DB_SETTINGS_FILE = \"dbsettings.json\"\n",
    "TABLE_NAME = \"embeddings\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Setup the database for Pgvector\n",
    "\n",
    "Fetch the dbsettings and instance the DB client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open( DB_SETTINGS_FILE, 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "    dbsettings = json.loads(content)\n",
    "\n",
    "# Setup the database client instance and connect\n",
    "db = PgClient(dbsettings)\n",
    "db.connect() # hardcoded to 'postgres' database for this demo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the setup statements to install the vector extension and create a new embeddings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"creating pgvector extension...\")\n",
    "db.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "db.register_vector()\n",
    "\n",
    "print(f\"creating {TABLE_NAME} table\")\n",
    "db.execute(f\"DROP TABLE IF EXISTS {TABLE_NAME};\")\n",
    "create_statement = f\"\"\"CREATE TABLE IF NOT EXISTS {TABLE_NAME} (\n",
    "                        id bigserial primary key, \n",
    "                        content text, \n",
    "                        source text, \n",
    "                        descriptions_embeddings vector({EMBEDDING_VECTOR_SIZE}));\"\"\"\n",
    "\n",
    "db.execute(create_statement)\n",
    "print(f\"{TABLE_NAME} table created\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the table with a simple query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez = db.query(f\"select id from {TABLE_NAME}\")\n",
    "print(\"records: \", len(rez))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 3. Setup the Text Embeddings model from a Sagemaker Endpoint\n",
    "\n",
    "Take a look at the Jumpstart FM text embedding options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_utils.list_jumpstart_models()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've already deployed the text embedding model to an endpoint. let's veryify by listing the currently deployed sagemaker endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_utils.list_endpoints()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the TEXT_EMBEDDING_ENDPOINT var to the correct endpoing name from the list above\n",
    "TEXT_EMBEDDING_ENDPOINT = \"### SET TEXT EMBEDDING ENDPOINT HERE ###\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 4. Create Text Embeddings\n",
    "\n",
    "Now let's use the text embedding endpoint to create our first embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First - create a Sagemaker session\n",
    "sm_session = Session()\n",
    "# Instantiate our endpoint model class\n",
    "embedder = SagemakerEmbeddingsModel(TEXT_EMBEDDING_ENDPOINT,sm_session)\n",
    "\n",
    "txt = \"LETS EMBED THIS TEXT!\"\n",
    "\n",
    "vec = embedder.query_endpoint(txt)\n",
    "print(\"\")\n",
    "print(vec)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 5. Vectorize an SEC filing document and store in Pgvector\n",
    "\n",
    "Integreate Langchain text splitter and tiktoken to create a document vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instance the vectorizor helper \n",
    "vectorizor = DocToVex(sm_session, TEXT_EMBEDDING_ENDPOINT)\n",
    "\n",
    "\n",
    "source_docs = [\n",
    "    \"data/financial/0000003153-20-000004.html\",\n",
    "]\n",
    "\n",
    "def read_doc_text(filename):\n",
    "    if \".html\" in filename:\n",
    "        print('parsing html')\n",
    "        with open(filename, 'r') as f:\n",
    "            soup = BeautifulSoup(f, 'html.parser')\n",
    "        # parse text from html file\n",
    "        text = soup.get_text()\n",
    "        text = text.replace(u'\\xa0', u' ')\n",
    "        text = text.replace(u'\\xa01', u' ')\n",
    "        text = text.replace(u'\\xa03', u' ')\n",
    "        text = text.replace(u'\\xa04', u' ')\n",
    "        return text\n",
    "\n",
    "    else:\n",
    "        print('parsing text')\n",
    "        with open(filename, \"r\") as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "\n",
    "for doc in source_docs:\n",
    "    # open doc and read all text\n",
    "    print(f'vectorizing {doc}')\n",
    "    doctext = read_doc_text(doc)\n",
    "\n",
    "    chunks, vex = vectorizor.get_document_vectors(doctext)\n",
    "    \n",
    "    # print(f'converted {len(vex)} chunks from source doc')\n",
    "    for i,chunk in enumerate(chunks):\n",
    "        docid = \"{}_{}\".format(doc, i)\n",
    "        vec = vex[i]\n",
    "        insert_query = \"insert into embeddings (content, source, descriptions_embeddings) values (%s, %s, %s)\"\n",
    "        insert_params = (chunk, docid, vec)\n",
    "        db.execute(insert_query, insert_params)\n",
    "\n",
    "print(\"\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Check the record count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rez = db.query(f\"select id, source from {TABLE_NAME}\")\n",
    "print(len(rez))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### 6. Test the database with some querying\n",
    "\n",
    "Create a text query, get a vector representation of it from our endpoint and then find similarities in the vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_question = \"Who is the Chief Executive Officer?\"\n",
    "# text_query = \"How many members are on the Board of Directors?\"\n",
    "\n",
    "# bring back our embedder from before to create a vector out of the query text\n",
    "question_embedding = embedder.query_endpoint(text_question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# now we query Pgvector with the embedded question to look for similar text chunks\n",
    "\n",
    "# <-> l2 distance\n",
    "# <=> cosine distance\n",
    "# <#> inner product\n",
    "# Note: <#> returns the negative inner product since Postgres only supports ASC order index scans on operators\n",
    "query = \"\"\"SELECT id, source, content,\n",
    "            descriptions_embeddings <-> '{}' as distance\n",
    "            FROM embeddings \n",
    "            ORDER BY descriptions_embeddings <-> '{}' limit 1;\"\"\".format(question_embedding,question_embedding)\n",
    "\n",
    "rez = db.query(query)\n",
    "\n",
    "print(rez[0][0], \"==\",rez[0][1])\n",
    "print(\"distance: \", rez[0][3])\n",
    "print(\"======================\")\n",
    "print(rez[0][2])\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### This concludes the Text Embeddings section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_embeddings",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
